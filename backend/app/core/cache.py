"""
Module de gestion du cache Redis pour le Simulateur RH

Ce module fournit des d√©corateurs et fonctions utilitaires pour :
- Mettre en cache les r√©sultats de fonctions
- Invalider le cache de mani√®re s√©lective
- G√©rer les cl√©s de cache de mani√®re coh√©rente
"""

import redis
from functools import wraps
import json
import hashlib
from typing import Optional, Callable, Any, Union
import logging
from datetime import timedelta

logger = logging.getLogger(__name__)

# Configuration Redis (√† adapter selon votre environnement)
REDIS_HOST = "localhost"
REDIS_PORT = 6379
REDIS_DB = 0
REDIS_PASSWORD = None  # Si n√©cessaire

# Initialisation du client Redis
try:
    redis_client = redis.Redis(
        host=REDIS_HOST,
        port=REDIS_PORT,
        db=REDIS_DB,
        password=REDIS_PASSWORD,
        decode_responses=True,
        socket_connect_timeout=5,
        socket_timeout=5,
        retry_on_timeout=True
    )
    # Test de connexion
    redis_client.ping()
    logger.info("‚úÖ Connexion Redis √©tablie avec succ√®s")
except redis.ConnectionError as e:
    logger.warning(f"‚ö†Ô∏è Redis non disponible : {e}. Le cache sera d√©sactiv√©.")
    redis_client = None
except Exception as e:
    logger.error(f"‚ùå Erreur Redis : {e}")
    redis_client = None


def _generate_cache_key(*args, **kwargs) -> str:
    """
    G√©n√®re une cl√© de cache unique bas√©e sur les arguments
    
    Args:
        *args: Arguments positionnels
        **kwargs: Arguments nomm√©s
        
    Returns:
        str: Hash MD5 des arguments
    """
    # Convertir les arguments en cha√Æne
    key_parts = []
    
    for arg in args:
        if isinstance(arg, (dict, list)):
            key_parts.append(json.dumps(arg, sort_keys=True, default=str))
        else:
            key_parts.append(str(arg))
    
    for k, v in sorted(kwargs.items()):
        if isinstance(v, (dict, list)):
            key_parts.append(f"{k}={json.dumps(v, sort_keys=True, default=str)}")
        else:
            key_parts.append(f"{k}={v}")
    
    key_data = "|".join(key_parts)
    return hashlib.md5(key_data.encode()).hexdigest()


def redis_cache(
    ttl: Union[int, timedelta] = 3600,
    prefix: str = "cache",
    key_builder: Optional[Callable] = None
):
    """
    D√©corateur pour mettre en cache les r√©sultats de fonction dans Redis
    
    Args:
        ttl: Dur√©e de vie du cache en secondes (ou timedelta)
        prefix: Pr√©fixe pour la cl√© de cache
        key_builder: Fonction personnalis√©e pour g√©n√©rer la cl√© de cache
        
    Usage:
        @redis_cache(ttl=3600, prefix="ref")
        def get_data(param1, param2):
            return expensive_operation(param1, param2)
    """
    if isinstance(ttl, timedelta):
        ttl = int(ttl.total_seconds())
    
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs) -> Any:
            # Si Redis n'est pas disponible, ex√©cuter directement
            if redis_client is None:
                return func(*args, **kwargs)
            
            # G√©n√©rer la cl√© de cache
            if key_builder:
                cache_key = key_builder(*args, **kwargs)
            else:
                cache_key = _generate_cache_key(*args, **kwargs)
            
            full_key = f"{prefix}:{func.__name__}:{cache_key}"
            
            # Tenter de r√©cup√©rer depuis le cache
            try:
                cached = redis_client.get(full_key)
                if cached:
                    logger.debug(f"‚úÖ Cache HIT: {full_key[:50]}...")
                    return json.loads(cached)
                else:
                    logger.debug(f"‚ùå Cache MISS: {full_key[:50]}...")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erreur lecture cache: {e}")
            
            # Ex√©cuter la fonction si pas en cache
            result = func(*args, **kwargs)
            
            # Stocker dans le cache
            try:
                redis_client.setex(
                    full_key,
                    ttl,
                    json.dumps(result, default=str, ensure_ascii=False)
                )
                logger.debug(f"üíæ Cache SET: {full_key[:50]}... (TTL: {ttl}s)")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erreur √©criture cache: {e}")
            
            return result
        
        # Ajouter une m√©thode pour invalider le cache de cette fonction
        def invalidate(*args, **kwargs):
            """Invalide le cache pour ces arguments sp√©cifiques"""
            if redis_client is None:
                return
            
            if key_builder:
                cache_key = key_builder(*args, **kwargs)
            else:
                cache_key = _generate_cache_key(*args, **kwargs)
            
            full_key = f"{prefix}:{func.__name__}:{cache_key}"
            try:
                redis_client.delete(full_key)
                logger.info(f"üóëÔ∏è Cache invalid√©: {full_key[:50]}...")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erreur invalidation cache: {e}")
        
        wrapper.invalidate = invalidate
        return wrapper
    
    return decorator


def invalidate_cache(pattern: str) -> int:
    """
    Invalide tous les caches correspondant au pattern
    
    Args:
        pattern: Pattern de cl√©s (ex: "ref:*", "ref:get_centres:*")
        
    Returns:
        int: Nombre de cl√©s supprim√©es
        
    Usage:
        invalidate_cache("ref:*")  # Invalide tous les r√©f√©rentiels
        invalidate_cache("ref:get_centres:*")  # Invalide seulement get_centres
    """
    if redis_client is None:
        logger.warning("Redis non disponible, impossible d'invalider le cache")
        return 0
    
    try:
        deleted = 0
        for key in redis_client.scan_iter(match=pattern):
            redis_client.delete(key)
            deleted += 1
        
        logger.info(f"üóëÔ∏è {deleted} cl√©s de cache invalid√©es (pattern: {pattern})")
        return deleted
    except Exception as e:
        logger.error(f"‚ùå Erreur invalidation cache: {e}")
        return 0


def clear_all_cache() -> bool:
    """
    Vide compl√®tement le cache Redis
    
    ‚ö†Ô∏è ATTENTION : Cette fonction supprime TOUTES les donn√©es du cache
    
    Returns:
        bool: True si succ√®s, False sinon
    """
    if redis_client is None:
        logger.warning("Redis non disponible")
        return False
    
    try:
        redis_client.flushdb()
        logger.warning("üóëÔ∏è TOUT le cache Redis a √©t√© vid√© !")
        return True
    except Exception as e:
        logger.error(f"‚ùå Erreur vidage cache: {e}")
        return False


def get_cache_stats() -> dict:
    """
    R√©cup√®re des statistiques sur le cache Redis
    
    Returns:
        dict: Statistiques du cache
    """
    if redis_client is None:
        return {"status": "unavailable"}
    
    try:
        info = redis_client.info()
        return {
            "status": "connected",
            "used_memory": info.get("used_memory_human", "N/A"),
            "total_keys": redis_client.dbsize(),
            "hits": info.get("keyspace_hits", 0),
            "misses": info.get("keyspace_misses", 0),
            "hit_rate": (
                info.get("keyspace_hits", 0) / 
                (info.get("keyspace_hits", 0) + info.get("keyspace_misses", 1))
            ) * 100
        }
    except Exception as e:
        logger.error(f"‚ùå Erreur r√©cup√©ration stats: {e}")
        return {"status": "error", "message": str(e)}


# D√©corateurs sp√©cialis√©s pour diff√©rents types de donn√©es

def cache_referentiel(ttl: int = 7200):
    """
    Cache sp√©cifique pour les r√©f√©rentiels (2h par d√©faut)
    Les r√©f√©rentiels changent rarement
    """
    return redis_cache(ttl=ttl, prefix="ref")


def cache_simulation(ttl: int = 1800):
    """
    Cache sp√©cifique pour les simulations (30min par d√©faut)
    Les simulations peuvent √™tre recalcul√©es plus fr√©quemment
    """
    return redis_cache(ttl=ttl, prefix="sim")


def cache_user_data(ttl: int = 300):
    """
    Cache sp√©cifique pour les donn√©es utilisateur (5min par d√©faut)
    Donn√©es volatiles qui changent fr√©quemment
    """
    return redis_cache(ttl=ttl, prefix="user")


# Exemple d'utilisation
if __name__ == "__main__":
    # Test du cache
    @redis_cache(ttl=60, prefix="test")
    def expensive_function(x, y):
        """Fonction co√ªteuse √† calculer"""
        import time
        time.sleep(2)  # Simule un calcul long
        return x + y
    
    print("Premier appel (sans cache)...")
    result1 = expensive_function(5, 3)
    print(f"R√©sultat: {result1}")
    
    print("\nDeuxi√®me appel (avec cache)...")
    result2 = expensive_function(5, 3)
    print(f"R√©sultat: {result2}")
    
    print("\nStatistiques du cache:")
    print(get_cache_stats())
    
    print("\nInvalidation du cache...")
    expensive_function.invalidate(5, 3)
    
    print("\nTroisi√®me appel (cache invalid√©)...")
    result3 = expensive_function(5, 3)
    print(f"R√©sultat: {result3}")
